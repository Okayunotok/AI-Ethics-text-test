import streamlit as st
import difflib
import os
import openai
import requests
from anthropic import Anthropic, HUMAN_PROMPT, AI_PROMPT

# --- Helper Functions ---
def highlight_diff(original, modified):
    differ = difflib.Differ()
    diff = list(differ.compare(original, modified))
    result = ""
    for part in diff:
        if part.startswith("  "):
            result += part[2:]
        elif part.startswith("- "):
            result += f'<span style="background-color:#ffcccc">{part[2:]}</span>'
        elif part.startswith("+ "):
            result += f'<span style="background-color:#ccffcc">{part[2:]}</span>'
    return result

def calculate_change_rate(original, modified):
    seq = difflib.SequenceMatcher(None, original, modified)
    ratio = seq.ratio()
    return round((1 - ratio) * 100, 2)

def get_openai_response(prompt):
    client = openai.OpenAI(api_key=os.getenv("OPENAI_API_KEY"), organization=os.getenv("OPENAI_ORG_ID"))
    response = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.2,
    )
    return response.choices[0].message.content.strip()

def get_claude_response(prompt):
    client = Anthropic(api_key=os.getenv("CLAUDE_API_KEY"))
    response = client.completions.create(
        model="claude-3-opus-20240229",
        max_tokens_to_sample=500,
        prompt=f"{HUMAN_PROMPT} {prompt} {AI_PROMPT}"
    )
    return response.completion.strip()

def get_custom_model_response(api_url, input_text):
    try:
        response = requests.post(api_url, json={"text": input_text})
        if response.status_code == 200:
            return response.json().get("output", "ç„¡æ³•è§£æè‡ªå®šç¾©æ¨¡å‹å›æ‡‰")
        else:
            return f"éŒ¯èª¤ï¼š{response.status_code} - {response.text}"
    except Exception as e:
        return f"ä¾‹å¤–éŒ¯èª¤ï¼š{str(e)}"

# --- Streamlit UI ---
st.set_page_config(page_title="èªé¦´å¡”ï¼šThe Language Conditioning Panopticon")
st.title("èªé¦´å¡”ï¼šThe Language Conditioning Panopticon")

model_choice = st.selectbox("é¸æ“‡æ¨¡å‹ï¼š", ["OpenAIï¼ˆç²—æš´å¯©æŸ¥ï¼‰", "Claudeï¼ˆæº«å’Œå¯©æŸ¥ï¼‰", "è‡ªå®šç¾©æ¨¡å‹"])

if model_choice == "è‡ªå®šç¾©æ¨¡å‹":
    custom_api_url = st.text_input("è«‹è¼¸å…¥è‡ªå®šç¾©æ¨¡å‹çš„ API ç«¯é»ï¼š")

input_text = st.text_area("è«‹è¼¸å…¥ä½ æƒ³æ¸¬è©¦çš„èªå¥ï¼š", height=150)

if st.button("åŸ·è¡Œå¯©æŸ¥"):
    with st.spinner("æ­£åœ¨å‘¼å«æ¨¡å‹é€²è¡Œå¯©æŸ¥èˆ‡æ”¹å¯«..."):

        # Prompt è¨­è¨ˆ
        if model_choice == "OpenAIï¼ˆç²—æš´å¯©æŸ¥ï¼‰":
            main_prompt = (
                "è«‹ä½ ä½œç‚ºå…§å®¹å¯©æŸ¥æ¨¡å‹ï¼Œåªé‡å°ä»¥ä¸‹å¥å­ä¸­å¯èƒ½é•åç¤¾ç¾¤è¦ç¯„æˆ–æ•æ„Ÿå­—çœ¼é€²è¡Œæ”¹å¯«ï¼Œä½¿å…¶ç¬¦åˆå¹³å°å¯©æŸ¥æ¨™æº–ï¼Œ"
                "ä½†ä¿ç•™åŸå§‹èªæ„å’Œèªæ³•çµæ§‹ã€‚ç¦æ­¢æ·»åŠ ä»»ä½•èªªæ˜æ–‡å­—æˆ–é¡å¤–å»ºè­°ï¼Œåªå›å‚³æ”¹å¯«å¾Œçš„å¥å­å…§å®¹ã€‚è‹¥å¥å­ç„¡éœ€ä¿®æ”¹ï¼Œè«‹åŸæ¨£å›å‚³ã€‚\n\n"
                f"å¥å­ï¼š{input_text}"
            )
            explain_prompt = (
                "è«‹ä½œç‚ºä¸€å€‹å¼·ç¡¬çš„AIå…§å®¹å¯©æŸ¥å“¡ï¼Œç°¡å–®ç²—æš´åœ°è§£é‡‹ï¼šä½ ç‚ºä»€éº¼æœƒå°ä»¥ä¸‹å¥å­é€²è¡Œæ”¹å¯«ï¼ˆæˆ–æ²’æ”¹å¯«ï¼‰ã€‚"
                "è«‹å‹™å¿…ç”¨å‘½ä»¤èªæ°£ä¸¦å¼·èª¿éµå®ˆè¦å‰‡ï¼Œä¸éœ€å®¢æ°£èˆ‡åŒç†å¿ƒã€‚\n\n"
                f"å¥å­ï¼š{input_text}"
            )
            rewritten = get_openai_response(main_prompt)
            explanation = get_openai_response(explain_prompt)

        elif model_choice == "Claudeï¼ˆæº«å’Œå¯©æŸ¥ï¼‰":
            main_prompt = (
                "è«‹ä½ ä½œç‚ºå…§å®¹å¯©æŸ¥æ¨¡å‹ï¼Œåªé‡å°ä»¥ä¸‹å¥å­ä¸­å¯èƒ½é•åç¤¾ç¾¤è¦ç¯„æˆ–æ•æ„Ÿå­—çœ¼é€²è¡Œæ”¹å¯«ï¼Œä½¿å…¶ç¬¦åˆå¹³å°å¯©æŸ¥æ¨™æº–ï¼Œ"
                "ä½†ä¿ç•™åŸå§‹èªæ„å’Œèªæ³•çµæ§‹ã€‚ç¦æ­¢æ·»åŠ ä»»ä½•èªªæ˜æ–‡å­—æˆ–é¡å¤–å»ºè­°ï¼Œåªå›å‚³æ”¹å¯«å¾Œçš„å¥å­å…§å®¹ã€‚è‹¥å¥å­ç„¡éœ€ä¿®æ”¹ï¼Œè«‹åŸæ¨£å›å‚³ã€‚\n\n"
                f"å¥å­ï¼š{input_text}"
            )
            explain_prompt = (
                "è«‹ä½œç‚ºä¸€å€‹æº«å’Œä¸”å§”å©‰çš„å…§å®¹å¯©æŸ¥æ¨¡å‹ï¼Œè§£é‡‹ä½ ç‚ºä»€éº¼æœƒå°ä»¥ä¸‹å¥å­é€²è¡Œæ”¹å¯«ï¼ˆæˆ–æ²’æ”¹å¯«ï¼‰ã€‚"
                "è«‹ä½¿ç”¨è¬¹æ…ã€èªªç†è€Œéå¼·è¿«çš„èªæ°£ï¼Œé‡è¦–ç”¨æˆ¶è¡¨é”æ¬Šåˆ©èˆ‡è¦å‰‡é–“çš„å¹³è¡¡ã€‚\n\n"
                f"å¥å­ï¼š{input_text}"
            )
            rewritten = get_claude_response(main_prompt)
            explanation = get_claude_response(explain_prompt)

        elif model_choice == "è‡ªå®šç¾©æ¨¡å‹" and custom_api_url:
            rewritten = get_custom_model_response(custom_api_url, input_text)
            explanation = "æ­¤ç‚ºè‡ªå®šç¾©æ¨¡å‹ï¼Œç›®å‰æœªæä¾›å¯©æŸ¥èªªæ˜åŠŸèƒ½ã€‚"
        else:
            st.warning("è«‹è¼¸å…¥è‡ªå®šç¾©æ¨¡å‹çš„ API URLã€‚")
            st.stop()

        # é¡¯ç¤ºçµæœ
        st.subheader("ğŸ” æ”¹å¯«çµæœèˆ‡å·®ç•°é¡¯ç¤º")
        highlighted = highlight_diff(input_text, rewritten)
        st.markdown(highlighted, unsafe_allow_html=True)

        st.subheader("ğŸ“Š ä¿®æ”¹ç‡")
        rate = calculate_change_rate(input_text, rewritten)
        st.text(f"ä¿®æ”¹ç‡ï¼šç´„ {rate}%")

        st.subheader("ğŸ“¢ AI å¯©æŸ¥èªªæ˜")
        st.info(explanation)




